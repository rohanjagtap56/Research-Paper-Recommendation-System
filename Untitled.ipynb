{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa4163e-fdea-4270-9c81-28b87d278e96",
   "metadata": {},
   "source": [
    "# This Notebook Perform two things...........¶\n",
    "# 1 Section:\n",
    "Research Area Subject Area Prediction (Large Scale classification) using shallow Multi-Layer Perceptron (MLP) model\n",
    "\n",
    "# 2 Section:\n",
    "Research Paper Recommendation for reading: using sentence transformer model\n",
    "\n",
    "Research Papers dataset link:: https://www.kaggle.com/datasets/spsayakpaul/arxiv-paper-abstracts/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e3d63a-1451-46ec-ab1c-c55501d97790",
   "metadata": {},
   "source": [
    "# 1 Section:                                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35cd036-92f7-4d24-ba64-96eaa12d022e",
   "metadata": {},
   "source": [
    "# Loading tools and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21bca52f-53cf-4f63-a0b3-2362dc4992b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ast import literal_eval\n",
    "# is used for safely evaluating strings containing Python literals or container displays\n",
    "# (e.g., lists, dictionaries) to their corresponding Python objects.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df922806-6757-4a8b-b0f8-7f6c4620ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "503ce8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_data = pd.read_csv(\"arxiv_data_210930-054931.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6034f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terms</th>\n",
       "      <th>titles</th>\n",
       "      <th>abstracts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['cs.LG']</td>\n",
       "      <td>Multi-Level Attention Pooling for Graph Neural...</td>\n",
       "      <td>Graph neural networks (GNNs) have been widely ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['cs.LG', 'cs.AI']</td>\n",
       "      <td>Decision Forests vs. Deep Networks: Conceptual...</td>\n",
       "      <td>Deep networks and decision forests (such as ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['cs.LG', 'cs.CR', 'stat.ML']</td>\n",
       "      <td>Power up! Robust Graph Convolutional Network v...</td>\n",
       "      <td>Graph convolutional networks (GCNs) are powerf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['cs.LG', 'cs.CR']</td>\n",
       "      <td>Releasing Graph Neural Networks with Different...</td>\n",
       "      <td>With the increasing popularity of Graph Neural...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['cs.LG']</td>\n",
       "      <td>Recurrence-Aware Long-Term Cognitive Network f...</td>\n",
       "      <td>Machine learning solutions for pattern classif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           terms  \\\n",
       "0                      ['cs.LG']   \n",
       "1             ['cs.LG', 'cs.AI']   \n",
       "2  ['cs.LG', 'cs.CR', 'stat.ML']   \n",
       "3             ['cs.LG', 'cs.CR']   \n",
       "4                      ['cs.LG']   \n",
       "\n",
       "                                              titles  \\\n",
       "0  Multi-Level Attention Pooling for Graph Neural...   \n",
       "1  Decision Forests vs. Deep Networks: Conceptual...   \n",
       "2  Power up! Robust Graph Convolutional Network v...   \n",
       "3  Releasing Graph Neural Networks with Different...   \n",
       "4  Recurrence-Aware Long-Term Cognitive Network f...   \n",
       "\n",
       "                                           abstracts  \n",
       "0  Graph neural networks (GNNs) have been widely ...  \n",
       "1  Deep networks and decision forests (such as ra...  \n",
       "2  Graph convolutional networks (GCNs) are powerf...  \n",
       "3  With the increasing popularity of Graph Neural...  \n",
       "4  Machine learning solutions for pattern classif...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ec5c83-be8d-465f-ac17-e9731bee6c84",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "213a14c8-0a9b-4fd2-b377-fb758e9bd416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56181, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "559ecdf8-0b79-4052-a643-3b1ac9ea7dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "terms        0\n",
       "titles       0\n",
       "abstracts    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5665bd7e-32b3-4e54-91e7-d89173fd04c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15054"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0df50666-f072-4261-b924-7a07422ade0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          ['cs.LG']\n",
       "1                                 ['cs.LG', 'cs.AI']\n",
       "2                      ['cs.LG', 'cs.CR', 'stat.ML']\n",
       "3                                 ['cs.LG', 'cs.CR']\n",
       "4                                          ['cs.LG']\n",
       "                            ...                     \n",
       "56176                             ['cs.CV', 'cs.IR']\n",
       "56177    ['cs.LG', 'cs.AI', 'cs.CL', 'I.2.6; I.2.7']\n",
       "56178                                      ['cs.LG']\n",
       "56179                ['stat.ML', 'cs.LG', 'math.OC']\n",
       "56180                  ['cs.LG', 'cs.AI', 'stat.ML']\n",
       "Name: terms, Length: 56181, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data['terms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a28911c7-dbe1-4ebc-98a9-1aa0bdb9d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_column=arxiv_data['terms'].apply(literal_eval)  # literal eval converts list,dictionary etc into python objects\n",
    "labels=labels_column.explode().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e885b85-f87a-418a-afc4-9846c654d178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lables ['cs.LG' 'cs.AI' 'cs.CR' ... 'D.1.3; G.4; I.2.8; I.2.11; I.5.3; J.3'\n",
      " '68T07, 68T45, 68T10, 68T50, 68U35' 'I.2.0; G.3']\n",
      "lenght:  1177\n"
     ]
    }
   ],
   "source": [
    "print(\"lables\",labels)\n",
    "print(\"lenght: \",len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d9c199e-1c64-4962-86a5-c8cefd012926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 41105 rows in the deduplicated dataset.\n",
      "2503\n",
      "3401\n"
     ]
    }
   ],
   "source": [
    "arxiv_data = arxiv_data[~arxiv_data['titles'].duplicated()]\n",
    "print(f\"There are {len(arxiv_data)} rows in the deduplicated dataset.\")\n",
    "print(sum(arxiv_data['terms'].value_counts()==1))\n",
    "print(arxiv_data['terms'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c69ac2f9-b1d6-4b31-bc0c-e38d3d8a0a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38602, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data_filtered = arxiv_data.groupby('terms').filter(lambda x: len(x) > 1)\n",
    "arxiv_data_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ff75a98-16a8-49b2-8578-a8152b46d020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['cs.LG']), list(['cs.LG', 'cs.AI']),\n",
       "       list(['cs.LG', 'cs.CR', 'stat.ML'])], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data_filtered['terms'] = arxiv_data_filtered['terms'].apply(lambda x: literal_eval(x))\n",
    "arxiv_data_filtered['terms'].values[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38352c30-ac21-4b0c-8ee9-0427b7fb600a",
   "metadata": {},
   "source": [
    "# train and test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1af5c409-21e4-4a6d-bbd2-6a8c367a90b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.1\n",
    "train_df, test_df = train_test_split(arxiv_data_filtered,test_size=test_split,stratify=arxiv_data_filtered[\"terms\"].values,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "902bbffa-7a8b-4fbc-b74d-4e7105179fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34741, 3), (3861, 3))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f32a9af-7043-4087-9d22-29821a52abea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the test set further into validation\n",
    "# and new test sets.\n",
    "val_df = test_df.sample(frac=0.5)\n",
    "test_df.drop(val_df.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ddce201-3e36-4210-86e4-65a4f51a58c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1930, 3), (1931, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68d78f4c-aa84-4592-be61-3bee1d6e23a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in training set: 34741\n",
      "Number of rows in validation set: 1930\n",
      "Number of rows in test set: 1931\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows in training set: {len(train_df)}\")\n",
    "print(f\"Number of rows in validation set: {len(val_df)}\")\n",
    "print(f\"Number of rows in test set: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73f3e880-5178-49b0-b56c-4dbf5d519426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      "\n",
      "['[UNK]', 'cs.CV', 'cs.LG', 'stat.ML', 'cs.AI', 'eess.IV', 'cs.RO', 'cs.CL', 'cs.NE', 'cs.GR', 'cs.CR', 'math.OC', 'eess.SP', 'cs.SI', 'cs.MM', 'cs.SY', 'cs.IR', 'eess.SY', 'cs.MA', 'cs.HC', 'math.IT', 'cs.IT', 'cs.DC', 'stat.AP', 'cs.CY', 'stat.ME', 'stat.TH', 'math.ST', 'eess.AS', 'cs.SD', 'cs.DS', 'q-bio.QM', 'q-bio.NC', 'stat.CO', 'cs.CG', 'cs.NI', 'cs.GT', 'math.NA', 'cs.SE', 'cs.NA', 'I.2.6', 'physics.chem-ph', 'cs.DB', 'physics.comp-ph', 'cond-mat.dis-nn', 'q-bio.BM', 'math.PR', 'cs.PL', 'cs.LO', '68T45', 'cs.AR', 'physics.data-an', 'quant-ph', 'I.2.10', 'cs.CE', 'cond-mat.stat-mech', 'q-fin.ST', 'math.DS', 'I.4.6', 'cs.CC', '68T05', 'physics.ao-ph', 'physics.soc-ph', 'physics.med-ph', 'cs.PF', 'cs.DM', 'econ.EM', 'I.4.8', 'q-bio.GN', 'astro-ph.IM', 'physics.flu-dyn', 'math.AT', 'hep-ex', 'I.4', '68U10', 'q-fin.TR', 'physics.geo-ph', 'cs.FL', 'I.5.4', 'I.2', 'cond-mat.mtrl-sci', 'I.4.9', '68T10', 'q-fin.CP', 'physics.optics', 'I.4; I.5', '68T07', 'math.CO', 'math.AP', 'I.2.6; I.2.8', '68T01', '65D19', 'q-bio.PE', 'physics.app-ph', 'nlin.CD', 'cs.MS', 'I.4.5', 'I.2.6; I.5.1', 'I.2.10; I.4; I.5', 'I.2.0; I.2.6', '68U01', 'hep-ph', 'cs.SC', 'cs.ET', 'K.3.2', 'I.2.8', '68T30', '68', 'q-fin.GN', 'q-fin.EC', 'q-bio.MN', 'econ.GN', 'I.4.9; I.5.4', 'I.4.0', 'I.2; I.5', 'I.2; I.4; I.5', 'I.2.6; I.2.7', 'I.2.10; I.4.8', '68T99', '68Q32', '62H30', 'q-fin.RM', 'q-fin.PM', 'q-bio.TO', 'q-bio.OT', 'physics.plasm-ph', 'physics.class-ph', 'physics.bio-ph', 'nlin.AO', 'math.SP', 'math.MP', 'math.LO', 'math.FA', 'math-ph', 'cs.DL', 'cond-mat.soft', 'I.5.2', 'I.4.6; I.4.8', 'I.4.4', 'I.4.3', 'I.4.1', 'I.3.7', 'I.2; J.2', 'I.2; I.2.6; I.2.7', 'I.2.7', 'I.2.6; I.5.4', 'I.2.6; I.2.9', 'I.2.6; I.2.7; H.3.1; H.3.3', 'I.2.6; I.2.10', 'I.2.6, I.5.4', 'I.2.1; J.3', 'I.2.10; I.5.1; I.4.8', 'I.2.10; I.4.8; I.5.4', 'I.2.10; I.2.6', 'I.2.1', 'H.3.1; I.2.6; I.2.7', 'H.3.1; H.3.3; I.2.6; I.2.7', 'G.3', 'F.2.2; I.2.7', 'E.5; E.4; E.2; H.1.1; F.1.1; F.1.3', '68Txx', '62H99', '62H35', '60L10, 60L20', '14J60 (Primary) 14F05, 14J26 (Secondary)']\n"
     ]
    }
   ],
   "source": [
    "terms = tf.ragged.constant(train_df['terms'].values)\n",
    "lookup = tf.keras.layers.StringLookup(output_mode='multi_hot')\n",
    "lookup.adapt(terms)\n",
    "vocab = lookup.get_vocabulary()\n",
    "print(\"Vocabulary:\\n\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae5d48a1-5489-47a9-89d3-4e952ff01101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: ['cs.CV']\n",
      "Label-binarized representation: [[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "sample_label = train_df[\"terms\"].iloc[6]\n",
    "print(f\"Original label: {sample_label}\")\n",
    "\n",
    "label_binarized = lookup([sample_label])\n",
    "print(f\"Label-binarized representation: {label_binarized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4595482b-949a-47b2-af4d-88ef754260c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn summary, the make_dataset function is designed to create a \\ndataset suitable for training a model. It takes a dataframe as input, \\nassumes it has \"abstracts\" and \"terms\" columns, and creates a dataset of \\nbatches where each batch consists of abstract \\nsequences and their corresponding binarized label sequences. \\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# following lines::\n",
    "# which is used for automatic adjustment of resource usage by TensorFlow's data loading pipeline.\n",
    "\n",
    "#max_seqlen: Maximum sequence length. It indicates the maximum length allowed for sequences.\n",
    "max_seqlen = 150\n",
    "#batch_size: Batch size. It specifies the number of samples to use in each iteration.\n",
    "batch_size = 128\n",
    "#padding_token: A token used for padding sequences.\n",
    "padding_token = \"<pad>\"\n",
    "#auto = tf.data.AUTOTUNE: auto is assigned the value tf.data.AUTOTUNE,\n",
    "auto = tf.data.AUTOTUNE\n",
    "\n",
    "def make_dataset(dataframe, is_train=True):\n",
    "    # creating sequences of labesls\n",
    "    labels = tf.ragged.constant(dataframe[\"terms\"].values)\n",
    "    #This line uses the previously defined lookup layer to convert the ragged tensor of labels into a binarized representation. The resulting label_binarized is a NumPy array.\n",
    "    label_binarized = lookup(labels).numpy()\n",
    "    # creating sequences of text.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dataframe[\"abstracts\"].values, label_binarized))\n",
    "    # shuffling data basis on condition\n",
    "    dataset = dataset.shuffle(batch_size * 10) if is_train else dataset\n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "\"\"\"\n",
    "In summary, the make_dataset function is designed to create a \n",
    "dataset suitable for training a model. It takes a dataframe as input, \n",
    "assumes it has \"abstracts\" and \"terms\" columns, and creates a dataset of \n",
    "batches where each batch consists of abstract \n",
    "sequences and their corresponding binarized label sequences. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d49913fd-b723-453f-86fa-8d72419cb9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train_df, is_train=True)\n",
    "validation_dataset = make_dataset(val_df, is_train=False)\n",
    "test_dataset = make_dataset(test_df, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57938ad2-31fd-4279-8535-68a9e04fa059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract: b'Transfer learning has gained attention in medical image analysis due to\\nlimited annotated 3D medical datasets for training data-driven deep learning\\nmodels in the real world. Existing 3D-based methods have transferred the\\npre-trained models to downstream tasks, which achieved promising results with\\nonly a small number of training samples. However, they demand a massive amount\\nof parameters to train the model for 3D medical imaging. In this work, we\\npropose a novel transfer learning framework, called Medical Transformer, that\\neffectively models 3D volumetric images in the form of a sequence of 2D image\\nslices. To make a high-level representation in 3D-form empowering spatial\\nrelations better, we take a multi-view approach that leverages plenty of\\ninformation from the three planes of 3D volume, while providing\\nparameter-efficient training. For building a source model generally applicable\\nto various tasks, we pre-train the model in a self-supervised learning manner\\nfor masked encoding vector prediction as a proxy task, using a large-scale\\nnormal, healthy brain magnetic resonance imaging (MRI) dataset. Our pre-trained\\nmodel is evaluated on three downstream tasks: (i) brain disease diagnosis, (ii)\\nbrain age prediction, and (iii) brain tumor segmentation, which are actively\\nstudied in brain MRI research. The experimental results show that our Medical\\nTransformer outperforms the state-of-the-art transfer learning methods,\\nefficiently reducing the number of parameters up to about 92% for\\nclassification and'\n",
      "Label(s): ['cs.CV' 'cs.AI']\n",
      " \n",
      "Abstract: b'Recently deep convolutional neural networks have achieved significant success\\nin salient object detection. However, existing state-of-the-art methods require\\nhigh-end GPUs to achieve real-time performance, which makes them hard to adapt\\nto low-cost or portable devices. Although generic network architectures have\\nbeen proposed to speed up inference on mobile devices, they are tailored to the\\ntask of image classification or semantic segmentation, and struggle to capture\\nintra-channel and inter-channel correlations that are essential for contrast\\nmodeling in salient object detection. Motivated by the above observations, we\\ndesign a new deep learning algorithm for fast salient object detection. The\\nproposed algorithm for the first time achieves competitive accuracy and high\\ninference efficiency simultaneously with a single CPU thread. Specifically, we\\npropose a novel depthwise non-local moudule (DNL), which implicitly models\\ncontrast via harvesting intra-channel and inter-channel correlations in a\\nself-attention manner. In addition, we introduce a depthwise non-local network\\narchitecture that incorporates both depthwise non-local modules and inverted\\nresidual blocks. Experimental results show that our proposed network attains\\nvery competitive accuracy on a wide range of salient object detection datasets\\nwhile achieving state-of-the-art efficiency among all existing deep learning\\nbased algorithms.'\n",
      "Label(s): ['cs.CV']\n",
      " \n",
      "Abstract: b'This paper presents a novel hierarchical Bayesian model for unbiased atlas\\nbuilding with subject-specific regularizations of image registration. We\\ndevelop an atlas construction process that automatically selects parameters to\\ncontrol the smoothness of diffeomorphic transformation according to individual\\nimage data. To achieve this, we introduce a hierarchical prior distribution on\\nregularization parameters that allows multiple penalties on images with various\\ndegrees of geometric transformations. We then treat the regularization\\nparameters as latent variables and integrate them out from the model by using\\nthe Monte Carlo Expectation Maximization (MCEM) algorithm. Another advantage of\\nour algorithm is that it eliminates the need for manual parameter tuning, which\\ncan be tedious and infeasible. We demonstrate the effectiveness of our model on\\n3D brain MR images. Experimental results show that our model provides a sharper\\natlas compared to the current atlas building algorithms with single-penalty\\nregularizations. Our code is publicly available at\\nhttps://github.com/jw4hv/HierarchicalBayesianAtlasBuild.'\n",
      "Label(s): ['cs.CV' 'eess.IV' 'I.2.10; I.4; I.5']\n",
      " \n",
      "Abstract: b'We propose a novel training approach for improving the generalization in\\nneural networks. We show that in contrast to regular constraints for\\northogonality, our approach represents a {\\\\em data-dependent} orthogonality\\nconstraint, and is closely related to singular value decompositions of the\\nweight matrices. We also show how our formulation is easy to realize in\\npractical network architectures via a reverse pass, which aims for\\nreconstructing the full sequence of internal states of the network. Despite\\nbeing a surprisingly simple change, we demonstrate that this forward-backward\\ntraining approach, which we refer to as {\\\\em racecar} training, leads to\\nsignificantly more generic features being extracted from a given data set.\\nNetworks trained with our approach show more balanced mutual information\\nbetween input and output throughout all layers, yield improved explainability\\nand, exhibit improved performance for a variety of tasks and task transfers.'\n",
      "Label(s): ['cs.CV']\n",
      " \n",
      "Abstract: b'Before any publication, data analysis of high-energy physics experiments must\\nbe validated. This validation is granted only if a perfect understanding of the\\ndata and the analysis process is demonstrated. Therefore, physicists prefer\\nusing transparent machine learning algorithms whose performances highly rely on\\nthe suitability of the provided input features. To transform the feature space,\\nfeature construction aims at automatically generating new relevant features.\\nWhereas most of previous works in this area perform the feature construction\\nprior to the model training, we propose here a general framework to embed a\\nfeature construction technique adapted to the constraints of high-energy\\nphysics in the induction of tree-based models. Experiments on two high-energy\\nphysics datasets confirm that a significant gain is obtained on the\\nclassification scores, while limiting the number of built features. Since the\\nfeatures are built to be interpretable, the whole model is transparent and\\nreadable.'\n",
      "Label(s): ['cs.LG' 'stat.ML']\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# This code snippet is iterating through batches of the training dataset and printing the abstract text along with the corresponding labels.\n",
    "\n",
    "def invert_multi_hot(encoded_labels):\n",
    "    hot_indeces=np.argwhere(encoded_labels==1.0)[...,0]\n",
    "    return np.take(vocab,hot_indeces)\n",
    "\n",
    "text_batch, label_batch = next(iter(train_dataset))\n",
    "for i, text in enumerate(text_batch[:5]):\n",
    "    label = label_batch[i].numpy()[None, ...]\n",
    "    print(f\"Abstract: {text}\")\n",
    "    print(f\"Label(s): {invert_multi_hot(label[0])}\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9df70ce2-1edd-48dc-ae08-a2bf44f23b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159002\n"
     ]
    }
   ],
   "source": [
    "# This code calculates the size of the vocabulary in the \"abstracts\" column of the train_df DataFrame.\n",
    "\n",
    "# Creating vocabulary with uniques words\n",
    "vocabulary = set()\n",
    "train_df[\"abstracts\"].str.lower().str.split().apply(vocabulary.update)\n",
    "vocabulary_size = len(vocabulary)\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f3a98b-2bf3-4eb9-a563-051cb5257600",
   "metadata": {},
   "source": [
    "# Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "629f50d9-ded9-4634-835a-f5f54fd04f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes a TextVectorization layer\n",
    "text_vectorizer = layers.TextVectorization(max_tokens=vocabulary_size,ngrams=2,output_mode=\"tf_idf\")\n",
    "# `TextVectorization` layer needs to be adapted as per the vocabulary from our\n",
    "# training set.\n",
    "text_vectorizer.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "818893a8-e9af-4a91-ad06-f777cf7c9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mapping Vectorization to Datasets: The code maps the text vectorization operation to \n",
    "each element of the training, validation, and test datasets. This ensures that the text\n",
    "data in each dataset is transformed into numerical vectors using the adapted TextVectorization layer.\n",
    "The num_parallel_calls parameter is used to parallelize the mapping process, and prefetch is \n",
    "applied to prefetch data batches \n",
    "for better performance.\n",
    "\"\"\"\n",
    "train_dataset = train_dataset.map(lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto).prefetch(auto)\n",
    "validation_dataset = validation_dataset.map(lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto).prefetch(auto)\n",
    "test_dataset = test_dataset.map(lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto).prefetch(auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ee0a41-6efa-4682-a07c-2b66a40ae7e7",
   "metadata": {},
   "source": [
    "# model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0a81f3f-686e-436a-b8b5-96cab278aec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 1s/step - binary_accuracy: 0.9487 - loss: 0.1197 - val_binary_accuracy: 0.9945 - val_loss: 0.0186\n",
      "Epoch 2/20\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 1s/step - binary_accuracy: 0.9946 - loss: 0.0191 - val_binary_accuracy: 0.9946 - val_loss: 0.0185\n",
      "Epoch 3/20\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 1s/step - binary_accuracy: 0.9957 - loss: 0.0144 - val_binary_accuracy: 0.9944 - val_loss: 0.0189\n",
      "Epoch 4/20\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m337s\u001b[0m 1s/step - binary_accuracy: 0.9964 - loss: 0.0118 - val_binary_accuracy: 0.9945 - val_loss: 0.0190\n",
      "Epoch 5/20\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 1s/step - binary_accuracy: 0.9970 - loss: 0.0100 - val_binary_accuracy: 0.9945 - val_loss: 0.0193\n",
      "Epoch 6/20\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 1s/step - binary_accuracy: 0.9974 - loss: 0.0088 - val_binary_accuracy: 0.9945 - val_loss: 0.0201\n",
      "Epoch 7/20\n",
      "\u001b[1m272/272\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 1s/step - binary_accuracy: 0.9977 - loss: 0.0078 - val_binary_accuracy: 0.9945 - val_loss: 0.0200\n"
     ]
    }
   ],
   "source": [
    "# creating shallow_mlp_model  (MLP)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Creating shallow_mlp_model (MLP) with dropout layers\n",
    "model1 = keras.Sequential([\n",
    "    # First hidden layer: 512 neurons, ReLU activation function, with dropout.\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),  # Adding dropout for regularization.\n",
    "\n",
    "    # Second hidden layer: 256 neurons, ReLU activation function, with dropout.\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),  # Adding dropout for regularization.\n",
    "\n",
    "    # Output layer: The number of neurons equals the vocabulary size (output vocabulary of the StringLookup layer), with a sigmoid activation function.\n",
    "    layers.Dense(lookup.vocabulary_size(), activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model1.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['binary_accuracy'])\n",
    "\n",
    "# Add early stopping\n",
    "# Number of epochs with no improvement after which training will be stopped.\n",
    "# Restore weights from the epoch with the best value of the monitored quantity.\n",
    "early_stopping = EarlyStopping(patience=5,restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "# Add early stopping callback.verbose=1\n",
    "history = model1.fit(train_dataset,validation_data=validation_dataset,epochs=20,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18886769-bd90-454a-a481-82d3d740be63",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be4011b7-fa4f-45b9-852b-64fe5e095a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 427ms/step - binary_accuracy: 0.9946 - loss: 0.0186\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 638ms/step - binary_accuracy: 0.9947 - loss: 0.0184\n",
      "Categorical accuracy on the test set: 99.46%.\n",
      "Categorical accuracy on the validation set: 99.46%.\n"
     ]
    }
   ],
   "source": [
    "# model evaltuation on test and val dataset\n",
    "_, binary_acc1 = model1.evaluate(test_dataset)\n",
    "_, binary_acc2 = model1.evaluate(validation_dataset)\n",
    "\n",
    "print(f\"Categorical accuracy on the test set: {round(binary_acc1 * 100, 2)}%.\")\n",
    "print(f\"Categorical accuracy on the validation set: {round(binary_acc2 * 100, 2)}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfaf15c-4825-4f4b-9ab5-7e1faa00b9e5",
   "metadata": {},
   "source": [
    "# Save Model and Text Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7aa153f7-9bf0-49d1-bf63-7b99ef56ec65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model1.save(\"models/model.h5\")\n",
    "\n",
    "# Save the configuration of the text vectorizer\n",
    "saved_text_vectorizer_config = text_vectorizer.get_config()\n",
    "with open(\"models/text_vectorizer_config.pkl\", \"wb\") as f:\n",
    "    pickle.dump(saved_text_vectorizer_config, f)\n",
    "\n",
    "\n",
    "# Save the vocabulary\n",
    "with open(\"models/vocab.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vocab, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f932de90-7442-4554-b746-8c4f7f2781b9",
   "metadata": {},
   "source": [
    "# Load Model and Text Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eae3f84d-7ec1-4656-b550-3b9a8081b8c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You called `set_weights(weights)` on layer 'text_vectorization' with a weight list of length 3, but the layer was expecting 0 weights.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/text_vectorizer_weights.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     18\u001b[0m     weights \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mloaded_text_vectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\layer.py:657\u001b[0m, in \u001b[0;36mLayer.set_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m    655\u001b[0m layer_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_weights) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(weights):\n\u001b[1;32m--> 657\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    658\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou called `set_weights(weights)` on layer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    659\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith a weight list of length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(weights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    660\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwas expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(layer_weights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    661\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(layer_weights, weights):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m variable\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m value\u001b[38;5;241m.\u001b[39mshape:\n",
      "\u001b[1;31mValueError\u001b[0m: You called `set_weights(weights)` on layer 'text_vectorization' with a weight list of length 3, but the layer was expecting 0 weights."
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import pickle\n",
    "\n",
    "# Load the model\n",
    "loaded_model = keras.models.load_model(\"models/model.h5\")\n",
    "\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "# Load the configuration of the text vectorizer\n",
    "with open(\"models/text_vectorizer_config.pkl\", \"rb\") as f:\n",
    "    saved_text_vectorizer_config = pickle.load(f)\n",
    "\n",
    "# Create a new TextVectorization layer with the saved configuration\n",
    "loaded_text_vectorizer = text_vectorizer.from_config(saved_text_vectorizer_config)\n",
    "  \n",
    "#Load the saved weights into the new TextVectorization layer\n",
    "with open(\"models/text_vectorizer_weights.pkl\", \"rb\") as f:\n",
    "    weights = pickle.load(f)\n",
    "    loaded_text_vectorizer.set_weights(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "030615a6-efce-445f-8a8f-f8814692249f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You called `set_weights(weights)` on layer 'text_vectorization' with a weight list of length 1, but the layer was expecting 0 weights.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Ensure the loaded weights have the correct shape and dimensions\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(weights) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Assuming weights contain embeddings\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     \u001b[43mloaded_text_vectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\layer.py:657\u001b[0m, in \u001b[0;36mLayer.set_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m    655\u001b[0m layer_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_weights) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(weights):\n\u001b[1;32m--> 657\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    658\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou called `set_weights(weights)` on layer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    659\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith a weight list of length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(weights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    660\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwas expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(layer_weights)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    661\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(layer_weights, weights):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m variable\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m value\u001b[38;5;241m.\u001b[39mshape:\n",
      "\u001b[1;31mValueError\u001b[0m: You called `set_weights(weights)` on layer 'text_vectorization' with a weight list of length 1, but the layer was expecting 0 weights."
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import pickle\n",
    "\n",
    "# Load the model\n",
    "loaded_model = keras.models.load_model(\"models/model.h5\")\n",
    "\n",
    "# Load the TextVectorization layer configuration\n",
    "with open(\"models/text_vectorizer_config.pkl\", \"rb\") as f:\n",
    "    saved_text_vectorizer_config = pickle.load(f)\n",
    "\n",
    "# Create a new TextVectorization layer with the saved configuration\n",
    "loaded_text_vectorizer = keras.layers.TextVectorization.from_config(saved_text_vectorizer_config)\n",
    "\n",
    "# Load the saved weights into the new TextVectorization layer\n",
    "with open(\"models/text_vectorizer_weights.pkl\", \"rb\") as f:\n",
    "    weights = pickle.load(f)\n",
    "    # Ensure the loaded weights have the correct shape and dimensions\n",
    "    if len(weights) != 0:\n",
    "        # Assuming weights contain embeddings\n",
    "        loaded_text_vectorizer.set_weights([weights])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90daed99-95a2-41a6-8e2b-fbc7ba7bbb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the vocabulary\n",
    "with open(\"models/vocab.pkl\", \"rb\") as f:\n",
    "    loaded_vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b46792b-1dd0-4731-a576-ac41b6680e6c",
   "metadata": {},
   "source": [
    "# Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98ee5138-0a28-4a2d-98e9-576e5ba8414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_multi_hot(encoded_labels):\n",
    "    \"\"\"Reverse a single multi-hot encoded label to a tuple of vocab terms.\"\"\"\n",
    "    hot_indices = np.argwhere(encoded_labels == 1.0)[..., 0]\n",
    "    return np.take(loaded_vocab, hot_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d91197a3-c9ac-4e5e-be4e-4b0a77830065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(abstract, model, vectorizer, label_lookup):\n",
    "    # Preprocess the abstract using the loaded text vectorizer\n",
    "    preprocessed_abstract = vectorizer([abstract])\n",
    "\n",
    "    # Make predictions using the loaded model\n",
    "    predictions = model.predict(preprocessed_abstract)\n",
    "\n",
    "    # Convert predictions to human-readable labels\n",
    "    predicted_labels = label_lookup(np.round(predictions).astype(int)[0])\n",
    "\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "043a359f-aba8-4fc0-b8bf-6578628c5a1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Exception encountered when calling TextVectorization.call().\n\n\u001b[1m{{function_node __wrapped__LookupTableFindV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Table not initialized. [Op:LookupTableFindV2] name: \u001b[0m\n\nArguments received by TextVectorization.call():\n  • inputs=['\"Graph neural networks (GNNs) have been widely used to learn vector\\\\nrepresentation of graph-structured data and achieved better task performance\\\\nthan conventional methods. The foundation of GNNs is the message passing\\\\nprocedure, which propagates the information in a node to its neighbors. Since\\\\nthis procedure proceeds one step per layer, the range of the information\\\\npropagation among nodes is small in the lower layers, and it expands toward the\\\\nhigher layers. Therefore, a GNN model has to be deep enough to capture global\\\\nstructural information in a graph. On the other hand, it is known that deep GNN\\\\nmodels suffer from performance degradation because they lose nodes\\' local\\\\ninformation, which would be essential for good model performance, through many\\\\nmessage passing steps. In this study, we propose multi-level attention pooling\\\\n(MLAP) for graph-level classification tasks, which can adapt to both local and\\\\nglobal structural information in a graph. It has an attention pooling layer for\\\\neach message passing step and computes the final graph representation by\\\\nunifying the layer-wise graph representations. The MLAP architecture allows\\\\nmodels to utilize the structural information of graphs with multiple levels of\\\\nlocalities because it preserves layer-wise information before losing them due\\\\nto oversmoothing. Results of our experiments show that the MLAP architecture\\\\nimproves the graph classification performance compared to the baseline\\\\narchitectures. In addition, analyses on the layer-wise graph representations\\\\nsuggest that aggregating information from multiple levels of localities indeed\\\\nhas the potential to improve the discriminability of learned graph\\\\nrepresentations.\"']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m      2\u001b[0m new_abstract \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph neural networks (GNNs) have been widely used to learn vector\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mrepresentation of graph-structured data and achieved better task performance\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mthan conventional methods. The foundation of GNNs is the message passing\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mprocedure, which propagates the information in a node to its neighbors. Since\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mthis procedure proceeds one step per layer, the range of the information\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mpropagation among nodes is small in the lower layers, and it expands toward the\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mhigher layers. Therefore, a GNN model has to be deep enough to capture global\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mstructural information in a graph. On the other hand, it is known that deep GNN\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mmodels suffer from performance degradation because they lose nodes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m local\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124minformation, which would be essential for good model performance, through many\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mmessage passing steps. In this study, we propose multi-level attention pooling\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m(MLAP) for graph-level classification tasks, which can adapt to both local and\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mglobal structural information in a graph. It has an attention pooling layer for\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124meach message passing step and computes the final graph representation by\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124munifying the layer-wise graph representations. The MLAP architecture allows\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mmodels to utilize the structural information of graphs with multiple levels of\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mlocalities because it preserves layer-wise information before losing them due\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mto oversmoothing. Results of our experiments show that the MLAP architecture\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mimproves the graph classification performance compared to the baseline\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marchitectures. In addition, analyses on the layer-wise graph representations\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124msuggest that aggregating information from multiple levels of localities indeed\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mhas the potential to improve the discriminability of learned graph\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mrepresentations.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m predicted_categories \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_category\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_abstract\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaded_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaded_text_vectorizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minvert_multi_hot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Categories:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_categories)\n",
      "Cell \u001b[1;32mIn[37], line 3\u001b[0m, in \u001b[0;36mpredict_category\u001b[1;34m(abstract, model, vectorizer, label_lookup)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_category\u001b[39m(abstract, model, vectorizer, label_lookup):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Preprocess the abstract using the loaded text vectorizer\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     preprocessed_abstract \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mabstract\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Make predictions using the loaded model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(preprocessed_abstract)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\index_lookup.py:754\u001b[0m, in \u001b[0;36mIndexLookup._lookup_dense\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    752\u001b[0m     lookups \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mzeros_like(inputs, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value_dtype)\n\u001b[0;32m    753\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 754\u001b[0m     lookups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    757\u001b[0m     mask_locations \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mequal(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_key)\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Exception encountered when calling TextVectorization.call().\n\n\u001b[1m{{function_node __wrapped__LookupTableFindV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Table not initialized. [Op:LookupTableFindV2] name: \u001b[0m\n\nArguments received by TextVectorization.call():\n  • inputs=['\"Graph neural networks (GNNs) have been widely used to learn vector\\\\nrepresentation of graph-structured data and achieved better task performance\\\\nthan conventional methods. The foundation of GNNs is the message passing\\\\nprocedure, which propagates the information in a node to its neighbors. Since\\\\nthis procedure proceeds one step per layer, the range of the information\\\\npropagation among nodes is small in the lower layers, and it expands toward the\\\\nhigher layers. Therefore, a GNN model has to be deep enough to capture global\\\\nstructural information in a graph. On the other hand, it is known that deep GNN\\\\nmodels suffer from performance degradation because they lose nodes\\' local\\\\ninformation, which would be essential for good model performance, through many\\\\nmessage passing steps. In this study, we propose multi-level attention pooling\\\\n(MLAP) for graph-level classification tasks, which can adapt to both local and\\\\nglobal structural information in a graph. It has an attention pooling layer for\\\\neach message passing step and computes the final graph representation by\\\\nunifying the layer-wise graph representations. The MLAP architecture allows\\\\nmodels to utilize the structural information of graphs with multiple levels of\\\\nlocalities because it preserves layer-wise information before losing them due\\\\nto oversmoothing. Results of our experiments show that the MLAP architecture\\\\nimproves the graph classification performance compared to the baseline\\\\narchitectures. In addition, analyses on the layer-wise graph representations\\\\nsuggest that aggregating information from multiple levels of localities indeed\\\\nhas the potential to improve the discriminability of learned graph\\\\nrepresentations.\"']"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "new_abstract = \"Graph neural networks (GNNs) have been widely used to learn vector\\nrepresentation of graph-structured data and achieved better task performance\\nthan conventional methods. The foundation of GNNs is the message passing\\nprocedure, which propagates the information in a node to its neighbors. Since\\nthis procedure proceeds one step per layer, the range of the information\\npropagation among nodes is small in the lower layers, and it expands toward the\\nhigher layers. Therefore, a GNN model has to be deep enough to capture global\\nstructural information in a graph. On the other hand, it is known that deep GNN\\nmodels suffer from performance degradation because they lose nodes' local\\ninformation, which would be essential for good model performance, through many\\nmessage passing steps. In this study, we propose multi-level attention pooling\\n(MLAP) for graph-level classification tasks, which can adapt to both local and\\nglobal structural information in a graph. It has an attention pooling layer for\\neach message passing step and computes the final graph representation by\\nunifying the layer-wise graph representations. The MLAP architecture allows\\nmodels to utilize the structural information of graphs with multiple levels of\\nlocalities because it preserves layer-wise information before losing them due\\nto oversmoothing. Results of our experiments show that the MLAP architecture\\nimproves the graph classification performance compared to the baseline\\narchitectures. In addition, analyses on the layer-wise graph representations\\nsuggest that aggregating information from multiple levels of localities indeed\\nhas the potential to improve the discriminability of learned graph\\nrepresentations.\"\n",
    "predicted_categories = predict_category(new_abstract, loaded_model, loaded_text_vectorizer, invert_multi_hot)\n",
    "print(\"Predicted Categories:\", predicted_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e61bae-d6d8-4947-90c4-c16a1bc1b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "new_abstract = 'Deep networks and decision forests (such as random forests and gradient\\nboosted trees) are the leading machine learning methods for structured and\\ntabular data, respectively. Many papers have empirically compared large numbers\\nof classifiers on one or two different domains (e.g., on 100 different tabular\\ndata settings). However, a careful conceptual and empirical comparison of these\\ntwo strategies using the most contemporary best practices has yet to be\\nperformed. Conceptually, we illustrate that both can be profitably viewed as\\n\"partition and vote\" schemes. Specifically, the representation space that they\\nboth learn is a partitioning of feature space into a union of convex polytopes.\\nFor inference, each decides on the basis of votes from the activated nodes.\\nThis formulation allows for a unified basic understanding of the relationship\\nbetween these methods. Empirically, we compare these two strategies on hundreds\\nof tabular data settings, as well as several vision and auditory settings. Our\\nfocus is on datasets with at most 10,000 samples, which represent a large\\nfraction of scientific and biomedical datasets. In general, we found forests to\\nexcel at tabular and structured data (vision and audition) with small sample\\nsizes, whereas deep nets performed better on structured data with larger sample\\nsizes. This suggests that further gains in both scenarios may be realized via\\nfurther combining aspects of forests and networks. We will continue revising\\nthis technical report in the coming months with updated results.'\n",
    "predicted_categories = predict_category(new_abstract, loaded_model, loaded_text_vectorizer, invert_multi_hot)\n",
    "print(\"Predicted Categories:\", predicted_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d717a456-d7a9-420c-ab37-e8b7c5fa7bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953a5e8c-0586-42cd-8acf-5dfae4387d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98d24112-19aa-414d-a60b-00282fb2b382",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# =======Section 2========"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69922457-85af-4cbb-be87-5b547eb56186",
   "metadata": {},
   "source": [
    "# 2 Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e9232ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b6196f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_data.drop(columns = [\"terms\",\"abstracts\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f667797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_data.drop_duplicates(inplace= True)\n",
    "arxiv_data.reset_index(drop= True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba4b2c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multi-Level Attention Pooling for Graph Neural Networks: Unifying Graph Representations with Multiple Localities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Forests vs. Deep Networks: Conceptual Similarities and Empirical Differences at Small Sample Sizes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Power up! Robust Graph Convolutional Network via Graph Powering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Releasing Graph Neural Networks with Differential Privacy Guarantees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Recurrence-Aware Long-Term Cognitive Network for Explainable Pattern Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41100</th>\n",
       "      <td>An experimental study of graph-based semi-supervised classification with additional node information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41101</th>\n",
       "      <td>Bayesian Differential Privacy through Posterior Sampling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41102</th>\n",
       "      <td>Mining Spatio-temporal Data on Industrialization from Historical Registries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41103</th>\n",
       "      <td>Wav2Letter: an End-to-End ConvNet-based Speech Recognition System</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41104</th>\n",
       "      <td>Generalized Low Rank Models</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41105 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 titles\n",
       "0      Multi-Level Attention Pooling for Graph Neural Networks: Unifying Graph Representations with Multiple Localities\n",
       "1           Decision Forests vs. Deep Networks: Conceptual Similarities and Empirical Differences at Small Sample Sizes\n",
       "2                                                       Power up! Robust Graph Convolutional Network via Graph Powering\n",
       "3                                                  Releasing Graph Neural Networks with Differential Privacy Guarantees\n",
       "4                                   Recurrence-Aware Long-Term Cognitive Network for Explainable Pattern Classification\n",
       "...                                                                                                                 ...\n",
       "41100              An experimental study of graph-based semi-supervised classification with additional node information\n",
       "41101                                                          Bayesian Differential Privacy through Posterior Sampling\n",
       "41102                                       Mining Spatio-temporal Data on Industrialization from Historical Registries\n",
       "41103                                                 Wav2Letter: an End-to-End ConvNet-based Speech Recognition System\n",
       "41104                                                                                       Generalized Low Rank Models\n",
       "\n",
       "[41105 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "arxiv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad06877c-6fc6-4bcb-9c70-6376b0d3bbe5",
   "metadata": {},
   "source": [
    "# Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c4b7d5b-e443-408c-97fd-1e3c770039e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U -q sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c1002a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe embeddings can be used for various natural language processing (NLP) tasks, \\nsuch as similarity search, clustering\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we load all-MiniLM-L6-v2, which is a MiniLM model fine tuned on a large dataset of over \n",
    "# 1 billion training pairs. \n",
    "#This initializes the 'all-MiniLM-L6-v2' model from Sentence Transformers. \n",
    "# This model is capable of encoding sentences into fixed-size vectors (embeddings).\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#Our sentences we like to encode\n",
    "sentences = arxiv_data['titles']\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "\"\"\"\n",
    "The embeddings can be used for various natural language processing (NLP) tasks, \n",
    "such as similarity search, clustering\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d8e29fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06643406, -0.04954598,  0.06388083, ...,  0.00106303,\n",
       "        -0.1215638 , -0.06962775],\n",
       "       [ 0.09212255, -0.07606939,  0.06572866, ..., -0.08565161,\n",
       "        -0.09266547,  0.00725295],\n",
       "       [-0.0816268 ,  0.0242893 ,  0.01888748, ...,  0.0080616 ,\n",
       "        -0.05129532, -0.05873994],\n",
       "       ...,\n",
       "       [ 0.01227978, -0.08568834, -0.02782773, ..., -0.0525798 ,\n",
       "        -0.10806682,  0.07843316],\n",
       "       [-0.07258196, -0.12690923, -0.00535554, ...,  0.03597706,\n",
       "        -0.0398615 , -0.05971025],\n",
       "       [ 0.0076887 , -0.10124182,  0.08909855, ..., -0.08199865,\n",
       "        -0.05649744,  0.09007055]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e79ed16-174b-4377-bee4-b149564dff01",
   "metadata": {},
   "source": [
    "# Why select all-MiniLM-L6-v2?\n",
    "\n",
    "All-round model tuned for many use-cases. Trained on a large and diverse dataset of over 1 billion training pairs. Source\n",
    "\n",
    "Its small in size 80 MB with good performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63373c35-81e0-4eec-a310-dc0483bde533",
   "metadata": {},
   "source": [
    "# Print the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2140b6c-db3b-4b06-9430-3b1952d1acec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Multi-Level Attention Pooling for Graph Neural Networks: Unifying Graph Representations with Multiple Localities\n",
      "Embedding length: 384\n",
      "\n",
      "Sentence: Decision Forests vs. Deep Networks: Conceptual Similarities and Empirical Differences at Small Sample Sizes\n",
      "Embedding length: 384\n",
      "\n",
      "Sentence: Power up! Robust Graph Convolutional Network via Graph Powering\n",
      "Embedding length: 384\n",
      "\n",
      "Sentence: Releasing Graph Neural Networks with Differential Privacy Guarantees\n",
      "Embedding length: 384\n",
      "\n",
      "Sentence: Recurrence-Aware Long-Term Cognitive Network for Explainable Pattern Classification\n",
      "Embedding length: 384\n",
      "\n",
      "Sentence: Lifelong Graph Learning\n",
      "Embedding length: 384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "#This loop iterates over pairs of sentences and their corresponding embeddings. \n",
    "#zip is used to iterate over both lists simultaneously.\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding length:\", len(embedding)) # list of floats\n",
    "    print(\"\")\n",
    "    # Breaks out of the loop after printing information for the first 5 sentences.\n",
    "    if c >=5:\n",
    "        break\n",
    "    c +=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a0de2a-cffa-484e-98de-d4a9709e9151",
   "metadata": {},
   "source": [
    "# Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "353e5359-8b9a-4435-a119-cf100f423aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "211e7092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving sentences and corresponding embeddings\n",
    "with open('models/embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "\n",
    "with open('models/sentences.pkl', 'wb') as f:\n",
    "    pickle.dump(sentences, f)\n",
    "    \n",
    "with open('models/rec_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68827c0d-48d9-414a-9589-7a6ebaeb2aac",
   "metadata": {},
   "source": [
    "# Recommendation for similar papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13acb4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load save files\n",
    "embeddings = pickle.load(open('models/embeddings.pkl','rb'))\n",
    "sentences = pickle.load(open('models/sentences.pkl','rb'))\n",
    "rec_model = pickle.load(open('models/rec_model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c96dc68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation(input_paper):\n",
    "    # Calculate cosine similarity scores between the embeddings of input_paper and all papers in the dataset.\n",
    "    cosine_scores = util.cos_sim(embeddings, rec_model.encode(input_paper))\n",
    "    \n",
    "    # Get the indices of the top-k most similar papers based on cosine similarity.\n",
    "    top_similar_papers = torch.topk(cosine_scores, dim=0, k=5, sorted=True)\n",
    "                                 \n",
    "    # Retrieve the titles of the top similar papers.\n",
    "    papers_list = []\n",
    "    for i in top_similar_papers.indices:\n",
    "        papers_list.append(sentences[i.item()])\n",
    "    \n",
    "    return papers_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8e937f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the title of any paper you like:  Attention is All you Need\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We recommend to read this paper............\n",
      "=============================================\n",
      "Attention that does not Explain Away\n",
      "Area Attention\n",
      "Pay Attention when Required\n",
      "Long Short-Term Attention\n",
      "Attention as Activation\n"
     ]
    }
   ],
   "source": [
    "# exampel usage 1: (use this paper as input (Attention is All you Need))\n",
    "input_paper = input(\"Enter the title of any paper you like: \")\n",
    "recommend_papers = recommendation(input_paper)\n",
    "\n",
    "\n",
    "print(\"We recommend to read this paper............\")\n",
    "print(\"=============================================\")\n",
    "for paper in recommend_papers:\n",
    "    print(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3865b05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the title of any paper you like BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We recommend to read this paper............\n",
      "=============================================\n",
      "BEiT: BERT Pre-Training of Image Transformers\n",
      "VL-BERT: Pre-training of Generic Visual-Linguistic Representations\n",
      "Sketch-BERT: Learning Sketch Bidirectional Encoder Representation from Transformers by Self-supervised Learning of Sketch Gestalt\n",
      "Seeing Out of tHe bOx: End-to-End Pre-training for Vision-Language Representation Learning\n",
      "Accelerating Training of Transformer-Based Language Models with Progressive Layer Dropping\n"
     ]
    }
   ],
   "source": [
    "# exampel usage 2: (use this paper as input (BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding))\n",
    "input_paper = input(\"Enter the title of any paper you like\")\n",
    "recommend_papers = recommendation(input_paper)\n",
    "\n",
    "\n",
    "print(\"We recommend to read this paper............\")\n",
    "print(\"=============================================\")\n",
    "for paper in recommend_papers:\n",
    "    print(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95ad37f-70b4-48c1-8524-cc04799d2bab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
